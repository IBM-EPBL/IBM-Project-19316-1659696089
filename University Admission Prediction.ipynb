{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "IMPORT STATEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "DATA READING AND ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset/Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"Serial No.\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['GRE Score'],data['CGPA'])\n",
    "plt.title('CGPA vs GRE Score')\n",
    "plt.xlabel('GRE Score')\n",
    "plt.ylabel('CGPA')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['CGPA'],data['SOP'])\n",
    "plt.title('SOP for CGPA')\n",
    "plt.xlabel('CGPA')\n",
    "plt.ylabel('SOP')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.CGPA >= 8.5].plot(kind='scatter', x='GRE Score', y='TOEFL Score',color=\"BLUE\")\n",
    "\n",
    "plt.xlabel(\"GRE Score\")\n",
    "plt.ylabel(\"TOEFL SCORE\")\n",
    "plt.title(\"CGPA>=8.5\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"GRE Score\"].plot(kind = 'hist',bins = 200,figsize = (6,6))\n",
    "\n",
    "plt.title(\"GRE Scores\")\n",
    "plt.xlabel(\"GRE Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([data[\"TOEFL Score\"].min(),data[\"TOEFL Score\"].mean(),data[\"TOEFL Score\"].max()])\n",
    "r = [\"Worst\",\"Average\",\"Best\"]\n",
    "plt.bar(p,r)\n",
    "\n",
    "plt.title(\"TOEFL Scores\")\n",
    "plt.xlabel(\"Level\")\n",
    "plt.ylabel(\"TOEFL Score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.array([data[\"GRE Score\"].min(),data[\"GRE Score\"].mean(),data[\"GRE Score\"].max()])\n",
    "h = [\"Worst\",\"Average\",\"Best\"]\n",
    "plt.bar(g,h)\n",
    "\n",
    "plt.title(\"GRE Scores\")\n",
    "plt.xlabel(\"Level\")\n",
    "plt.ylabel(\"GRE Score\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(data.corr(), annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Research.value_counts()\n",
    "\n",
    "sns.countplot(x=\"University Rating\",data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"University Rating\", y=\"Chance of Admit \", data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.drop(['Chance of Admit '],axis=1) #input data_set\n",
    "y=data['Chance of Admit '] #output labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "MODELING AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rgr=RandomForestRegressor(random_state=1)\n",
    "rgr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=rgr.predict(X_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "import numpy as np\n",
    "print('Mean Absolute Error:', mean_absolute_error(y_test, y_predict))  \n",
    "print('Mean Squared Error:', mean_squared_error(y_test, y_predict))  \n",
    "print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (y_train>0.5)\n",
    "y_test = (y_test>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model._logistic import LogisticRegression\n",
    "\n",
    "lore = LogisticRegression(random_state=0, max_iter=1000)\n",
    "\n",
    "lr = lore.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_test, y_pred))  \n",
    "print('Recall Score:', recall_score(y_test, y_pred))  \n",
    "print('ROC AUC Score:', roc_auc_score(y_test, y_pred))\n",
    "print('Confussion Matrix:\\n', confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "SAVING THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lr, open(\"university.pkl\", \"wb\")) #logistic regression model\n",
    "pickle.dump(rgr, open(\"university_percent.pkl\", \"wb\")) #random forest regression model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3567043677e9e623e45f50147f63be11b9bb8088f85bef38c07137e8225ca207"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
